{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "class Ocr:\n",
    "    def __init__(self, img):\n",
    "        self.img = img\n",
    "\n",
    "    def text_detect(self):\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        reader = easyocr.Reader(['ko', 'en'], gpu = True)\n",
    "        result = reader.readtext(self.img)\n",
    "\n",
    "        # img = cv2.resize(img_cv2, (320, 448))\n",
    "        image = Image.fromarray(self.img)\n",
    "        font = ImageFont.truetype('C:/Users/tjoeun/AppData/Local/Microsoft/Windows/Fonts/NanumGothicBold.ttf', 10)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        np.random.seed(42)\n",
    "        COLORS = np.random.randint(0, 255, size=(255, 3),dtype=\"uint8\")\n",
    "        for i in result :\n",
    "            x = i[0][0][0] \n",
    "            y = i[0][0][1] \n",
    "            w = i[0][1][0] - i[0][0][0] \n",
    "            h = i[0][2][1] - i[0][1][1]\n",
    "\n",
    "            color_idx = random.randint(0,255) \n",
    "            color = [int(c) for c in COLORS[color_idx]]\n",
    "\n",
    "            draw.rectangle(((x, y), (x+w, y+h)), outline=tuple(color), width=2)\n",
    "            draw.text((int((x + x + w) / 2) , y-2),str(i[1]), font=font, fill=tuple(color),)\n",
    "\n",
    "        # plt.figure(figsize=(10,20))\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        # print(result)\n",
    "\n",
    "    def image_to_text(self):\n",
    "        # 추출된 텍스트 영역을 이용하여 각각의 텍스트를 잘라내고 EasyOCR을 다시 적용\n",
    "        reader = easyocr.Reader(['ko', 'en'], gpu=True)\n",
    "        result = reader.readtext(self.img)\n",
    "        \n",
    "        origin_results = []\n",
    "        roi_results = []\n",
    "        roi_gray_results =[]\n",
    "        roi_2_results =[]\n",
    "        roi_equal_results =[]\n",
    "        roi_dil_results =[]\n",
    "        roi_ero_results =[]\n",
    "        roi_canny_results =[]\n",
    "\n",
    "        for (box, text, confidence) in result:\n",
    "            try:\n",
    "                origin_results.append(text)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # 각 텍스트 박스의 좌표 추출\n",
    "            (startX, startY) = box[0]\n",
    "            (endX, endY) = box[2]\n",
    "            \n",
    "            # 좌표를 정수로 변환\n",
    "            startX, startY, endX, endY = int(startX), int(startY), int(endX), int(endY)\n",
    "\n",
    "            # print(startX, startY, endX, endY)\n",
    "            # 좌표가 음수이거나 이미지 범위를 벗어나는 경우 무시\n",
    "            if startX < 0 or startY < 0 or endX >= self.img.shape[1] or endY >= self.img.shape[0]:\n",
    "                continue\n",
    "\n",
    "            # 텍스트 영역 추출\n",
    "            roi = self.img[startY:endY, startX:endX]\n",
    "\n",
    "            ############################################# 이미지 전처리 ###################################################\n",
    "\n",
    "            # 이미지를 그레이스케일로 변환\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # 적응형 이진화 수행\n",
    "            roi_adaptive_thresh = cv2.adaptiveThreshold(roi_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "\n",
    "            # 히스토그램 평탄화 수행\n",
    "            roi_equalized = cv2.equalizeHist(roi_gray)\n",
    "\n",
    "            # 팽창\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            roi_dilation = cv2.dilate(roi, kernel, iterations=1)\n",
    "\n",
    "            # 침식\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            roi_erosion = cv2.erode(roi, kernel, iterations=1)\n",
    "\n",
    "            # 캐니\n",
    "            roi_canny = cv2.Canny(roi, 475, 500, apertureSize=3, L2gradient=True)\n",
    "\n",
    "            ############################################# 텍스트 인식 ###################################################\n",
    "\n",
    "            # 잘라낸 텍스트 영역에 EasyOCR을 적용\n",
    "            roi_result = reader.readtext(roi)\n",
    "            roi_gray_result = reader.readtext(roi_gray)\n",
    "            roi_2_result = reader.readtext(roi_adaptive_thresh)\n",
    "            roi_equal_result = reader.readtext(roi_equalized)\n",
    "            roi_dil_result = reader.readtext(roi_dilation)\n",
    "            roi_ero_result = reader.readtext(roi_erosion)\n",
    "            roi_canny_result = reader.readtext(roi_canny)\n",
    "\n",
    "            ############################################# 결과 출력 ###################################################\n",
    "\n",
    "            # print(\"부분\")\n",
    "            # plt.imshow(roi)\n",
    "            try:\n",
    "                # print(f'Text: {roi_result[0][1]}, Confidence: {roi_result[0][2]}')\n",
    "                roi_results.append(roi_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"그레이 스케일\")\n",
    "            # plt.imshow(roi_gray, cmap=\"gray\")\n",
    "            try:\n",
    "                # print(f'Text: {roi_gray_result[0][1]}, Confidence: {roi_gray_result[0][2]}')\n",
    "                roi_gray_results.append(roi_gray_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_gray_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"적응형 이진화\")\n",
    "            # plt.imshow(roi_adaptive_thresh, cmap=\"gray\")\n",
    "            try:\n",
    "                # print(f'Text: {roi_2_result[0][1]}, Confidence: {roi_2_result[0][2]}')\n",
    "                roi_2_results.append(roi_2_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_2_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"히스토그램 평탄화\")\n",
    "            # plt.imshow(roi_equalized)\n",
    "            try:\n",
    "                # print(f'Text: {roi_equal_result[0][1]}, Confidence: {roi_equal_result[0][2]}')\n",
    "                roi_equal_results.append(roi_equal_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_equal_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"팽창\")\n",
    "            # plt.imshow(roi_dilation)\n",
    "            try:\n",
    "                # print(f'Text: {roi_dil_result[0][1]}, Confidence: {roi_dil_result[0][2]}')\n",
    "                roi_dil_results.append(roi_dil_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_dil_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"침식\")\n",
    "            # plt.imshow(roi_erosion)\n",
    "            try:\n",
    "                # print(f'Text: {roi_ero_result[0][1]}, Confidence: {roi_ero_result[0][2]}')\n",
    "                roi_ero_results.append(roi_ero_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_ero_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"캐니\")\n",
    "            # plt.imshow(roi_canny)\n",
    "            try:\n",
    "                # print(f'Text: {roi_canny_result[0][1]}, Confidence: {roi_canny_result[0][2]}')\n",
    "                roi_canny_results.append(roi_canny_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_canny_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "        return origin_results, roi_results, roi_gray_results, roi_2_results, roi_equal_results, roi_dil_results, roi_ero_results, roi_canny_results\n",
    "\n",
    "\n",
    "class Get_Nouns:\n",
    "    def __init__(self, i2t_text):\n",
    "        self.text = i2t_text\n",
    "\n",
    "    def get_nouns(self):\n",
    "        kkma = Kkma()\n",
    "        nouns = kkma.nouns(str(self.text))\n",
    "        return nouns\n",
    "\n",
    "    def get_nouns_list(self):\n",
    "        i2t_nouns = self.get_nouns()\n",
    "\n",
    "        noun_list = []\n",
    "\n",
    "        # 추출된 명사 출력\n",
    "        for i2t_noun in i2t_nouns:\n",
    "            if len(i2t_noun) > 1:\n",
    "                noun_list.append(i2t_noun)\n",
    "\n",
    "        # noun_list = list(set(noun_list))\n",
    "        return noun_list\n",
    "    \n",
    "    def get_nouns_freq(self, act_nouns, ani_nouns, com_nouns, dra_nouns, hor_nouns, etc_nouns):\n",
    "        self.act_nouns = act_nouns\n",
    "        self.ani_nouns = ani_nouns\n",
    "        self.com_nouns = com_nouns\n",
    "        self.dra_nouns = dra_nouns\n",
    "        self.hor_nouns = hor_nouns\n",
    "        self.etc_nouns = etc_nouns\n",
    "\n",
    "        nouns = self.get_nouns_list()\n",
    "        \n",
    "        act_freq = 0\n",
    "        ani_freq = 0\n",
    "        com_freq = 0\n",
    "        dra_freq = 0\n",
    "        hor_freq = 0\n",
    "        etc_freq = 0\n",
    "\n",
    "        # 입력한 단어들의 빈도수 확인\n",
    "        try:\n",
    "            for word in nouns:\n",
    "                if word in self.act_nouns:\n",
    "                    act_freq += 1\n",
    "                elif word in self.ani_nouns:\n",
    "                    ani_freq += 1\n",
    "                elif word in self.com_nouns:\n",
    "                    com_freq += 1\n",
    "                elif word in self.dra_nouns:\n",
    "                    dra_freq += 1\n",
    "                elif word in self.hor_nouns:\n",
    "                    hor_freq += 1\n",
    "                else:\n",
    "                    etc_freq += 1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return act_freq, ani_freq, com_freq, dra_freq, hor_freq, etc_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 장르별 단어 txt파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words_from_file(file_path):\n",
    "    words = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # 줄바꿈 문자를 제거하고 단어를 리스트에 추가\n",
    "            word = line.strip()\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "# 파일로부터 단어 리스트 불러오기\n",
    "act_nouns = read_words_from_file('c:/3rd_project/data/act_nouns.txt')\n",
    "ani_nouns = read_words_from_file('c:/3rd_project/data/ani_nouns.txt')\n",
    "com_nouns = read_words_from_file('c:/3rd_project/data/com_nouns.txt')\n",
    "dra_nouns = read_words_from_file('c:/3rd_project/data/dra_nouns.txt')\n",
    "hor_nouns = read_words_from_file('c:/3rd_project/data/hor_nouns.txt')\n",
    "etc_nouns = read_words_from_file('c:/3rd_project/data/etc_nouns.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 3, 2, 26, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('c:/3rd_project/data/images/movie/X_total_color.npy')\n",
    "y = np.load('c:/3rd_project/data/images/movie/y_total_color.npy')\n",
    "\n",
    "sample_img = X[7]\n",
    "sample_gen = y[0]\n",
    "\n",
    "img = sample_img\n",
    "genre = sample_gen\n",
    "\n",
    "\n",
    "## 이미지 텍스트 추출\n",
    "ocr = Ocr(img)\n",
    "# ocr.text_detect()\n",
    "i2t_text = ocr.image_to_text()\n",
    "# print(y[num])\n",
    "gn = Get_Nouns(i2t_text)\n",
    "nouns = gn.get_nouns_list()\n",
    "print(gn.get_nouns_freq(act_nouns, ani_nouns, com_nouns, dra_nouns, hor_nouns, etc_nouns))\n",
    "\n",
    "## 이미지 특징 추출\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
