{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('c:/3rd_project/data/images/movie/X_total_color.npy')\n",
    "y = np.load('c:/3rd_project/data/images/movie/y_total_color.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[245, 255, 255],\n",
       "        [242, 252, 254],\n",
       "        [246, 255, 255],\n",
       "        ...,\n",
       "        [250, 250, 252],\n",
       "        [254, 255, 255],\n",
       "        [254, 255, 255]],\n",
       "\n",
       "       [[194, 217, 231],\n",
       "        [197, 220, 233],\n",
       "        [194, 216, 229],\n",
       "        ...,\n",
       "        [245, 245, 247],\n",
       "        [240, 241, 243],\n",
       "        [238, 239, 241]],\n",
       "\n",
       "       [[193, 217, 227],\n",
       "        [193, 217, 228],\n",
       "        [194, 216, 227],\n",
       "        ...,\n",
       "        [250, 249, 254],\n",
       "        [249, 250, 252],\n",
       "        [241, 242, 244]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[241, 242, 244],\n",
       "        [241, 242, 244],\n",
       "        [241, 242, 244],\n",
       "        ...,\n",
       "        [239, 240, 242],\n",
       "        [240, 240, 242],\n",
       "        [240, 240, 242]],\n",
       "\n",
       "       [[241, 242, 244],\n",
       "        [241, 242, 244],\n",
       "        [241, 242, 244],\n",
       "        ...,\n",
       "        [239, 240, 242],\n",
       "        [240, 240, 242],\n",
       "        [240, 240, 242]],\n",
       "\n",
       "       [[241, 242, 244],\n",
       "        [241, 242, 244],\n",
       "        [241, 242, 244],\n",
       "        ...,\n",
       "        [239, 240, 242],\n",
       "        [240, 240, 242],\n",
       "        [240, 240, 242]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "num = 0\n",
    "img = X[num]\n",
    "\n",
    "# 이미지 표시\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "reader = easyocr.Reader(['ko','en'])\n",
    "result = reader.readtext(X[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "class Ocr:\n",
    "    def __init__(self, img):\n",
    "        self.img = img\n",
    "\n",
    "    def text_detect(self):\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        reader = easyocr.Reader(['ko', 'en'], gpu = True)\n",
    "        result = reader.readtext(self.img)\n",
    "\n",
    "        # img = cv2.resize(img_cv2, (320, 448))\n",
    "        image = Image.fromarray(self.img)\n",
    "        font = ImageFont.truetype('C:/Users/tjoeun/AppData/Local/Microsoft/Windows/Fonts/NanumGothicBold.ttf', 10)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        np.random.seed(42)\n",
    "        COLORS = np.random.randint(0, 255, size=(255, 3),dtype=\"uint8\")\n",
    "        for i in result :\n",
    "            x = i[0][0][0] \n",
    "            y = i[0][0][1] \n",
    "            w = i[0][1][0] - i[0][0][0] \n",
    "            h = i[0][2][1] - i[0][1][1]\n",
    "\n",
    "            color_idx = random.randint(0,255) \n",
    "            color = [int(c) for c in COLORS[color_idx]]\n",
    "\n",
    "            draw.rectangle(((x, y), (x+w, y+h)), outline=tuple(color), width=2)\n",
    "            draw.text((int((x + x + w) / 2) , y-2),str(i[1]), font=font, fill=tuple(color),)\n",
    "\n",
    "        # plt.figure(figsize=(10,20))\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        # print(result)\n",
    "\n",
    "    def image_to_text(self):\n",
    "        # 추출된 텍스트 영역을 이용하여 각각의 텍스트를 잘라내고 EasyOCR을 다시 적용\n",
    "        reader = easyocr.Reader(['ko', 'en'], gpu=True)\n",
    "        result = reader.readtext(self.img)\n",
    "        \n",
    "        origin_results = []\n",
    "        roi_results = []\n",
    "        roi_gray_results =[]\n",
    "        roi_2_results =[]\n",
    "        roi_equal_results =[]\n",
    "        roi_dil_results =[]\n",
    "        roi_ero_results =[]\n",
    "        roi_canny_results =[]\n",
    "\n",
    "        for (box, text, confidence) in result:\n",
    "            try:\n",
    "                origin_results.append(text)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # 각 텍스트 박스의 좌표 추출\n",
    "            (startX, startY) = box[0]\n",
    "            (endX, endY) = box[2]\n",
    "            \n",
    "            # 좌표를 정수로 변환\n",
    "            startX, startY, endX, endY = int(startX), int(startY), int(endX), int(endY)\n",
    "\n",
    "            # print(startX, startY, endX, endY)\n",
    "            # 좌표가 음수이거나 이미지 범위를 벗어나는 경우 무시\n",
    "            if startX < 0 or startY < 0 or endX >= self.img.shape[1] or endY >= self.img.shape[0]:\n",
    "                continue\n",
    "\n",
    "            # 텍스트 영역 추출\n",
    "            roi = self.img[startY:endY, startX:endX]\n",
    "\n",
    "            ############################################# 이미지 전처리 ###################################################\n",
    "\n",
    "            # 이미지를 그레이스케일로 변환\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # 적응형 이진화 수행\n",
    "            roi_adaptive_thresh = cv2.adaptiveThreshold(roi_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "\n",
    "            # 히스토그램 평탄화 수행\n",
    "            roi_equalized = cv2.equalizeHist(roi_gray)\n",
    "\n",
    "            # 팽창\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            roi_dilation = cv2.dilate(roi, kernel, iterations=1)\n",
    "\n",
    "            # 침식\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            roi_erosion = cv2.erode(roi, kernel, iterations=1)\n",
    "\n",
    "            # 캐니\n",
    "            roi_canny = cv2.Canny(roi, 475, 500, apertureSize=3, L2gradient=True)\n",
    "\n",
    "            ############################################# 텍스트 인식 ###################################################\n",
    "\n",
    "            # 잘라낸 텍스트 영역에 EasyOCR을 적용\n",
    "            roi_result = reader.readtext(roi)\n",
    "            roi_gray_result = reader.readtext(roi_gray)\n",
    "            roi_2_result = reader.readtext(roi_adaptive_thresh)\n",
    "            roi_equal_result = reader.readtext(roi_equalized)\n",
    "            roi_dil_result = reader.readtext(roi_dilation)\n",
    "            roi_ero_result = reader.readtext(roi_erosion)\n",
    "            roi_canny_result = reader.readtext(roi_canny)\n",
    "\n",
    "            ############################################# 결과 출력 ###################################################\n",
    "\n",
    "            # print(\"부분\")\n",
    "            # plt.imshow(roi)\n",
    "            try:\n",
    "                # print(f'Text: {roi_result[0][1]}, Confidence: {roi_result[0][2]}')\n",
    "                roi_results.append(roi_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"그레이 스케일\")\n",
    "            # plt.imshow(roi_gray, cmap=\"gray\")\n",
    "            try:\n",
    "                # print(f'Text: {roi_gray_result[0][1]}, Confidence: {roi_gray_result[0][2]}')\n",
    "                roi_gray_results.append(roi_gray_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_gray_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"적응형 이진화\")\n",
    "            # plt.imshow(roi_adaptive_thresh, cmap=\"gray\")\n",
    "            try:\n",
    "                # print(f'Text: {roi_2_result[0][1]}, Confidence: {roi_2_result[0][2]}')\n",
    "                roi_2_results.append(roi_2_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_2_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"히스토그램 평탄화\")\n",
    "            # plt.imshow(roi_equalized)\n",
    "            try:\n",
    "                # print(f'Text: {roi_equal_result[0][1]}, Confidence: {roi_equal_result[0][2]}')\n",
    "                roi_equal_results.append(roi_equal_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_equal_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"팽창\")\n",
    "            # plt.imshow(roi_dilation)\n",
    "            try:\n",
    "                # print(f'Text: {roi_dil_result[0][1]}, Confidence: {roi_dil_result[0][2]}')\n",
    "                roi_dil_results.append(roi_dil_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_dil_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"침식\")\n",
    "            # plt.imshow(roi_erosion)\n",
    "            try:\n",
    "                # print(f'Text: {roi_ero_result[0][1]}, Confidence: {roi_ero_result[0][2]}')\n",
    "                roi_ero_results.append(roi_ero_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_ero_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # print(\"캐니\")\n",
    "            # plt.imshow(roi_canny)\n",
    "            try:\n",
    "                # print(f'Text: {roi_canny_result[0][1]}, Confidence: {roi_canny_result[0][2]}')\n",
    "                roi_canny_results.append(roi_canny_result[0][1])\n",
    "            except:\n",
    "                # print(\"Not Detect\")\n",
    "                roi_canny_results.append('None')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "        return origin_results, roi_results, roi_gray_results, roi_2_results, roi_equal_results, roi_dil_results, roi_ero_results, roi_canny_results\n",
    "\n",
    "\n",
    "class Get_Nouns:\n",
    "    def __init__(self, i2t_text):\n",
    "        self.text = i2t_text\n",
    "\n",
    "    def get_nouns(self):\n",
    "        kkma = Kkma()\n",
    "        nouns = kkma.nouns(str(self.text))\n",
    "        return nouns\n",
    "\n",
    "    def get_nouns_list(self):\n",
    "        i2t_nouns = self.get_nouns()\n",
    "\n",
    "        noun_list = []\n",
    "\n",
    "        # 추출된 명사 출력\n",
    "        for i2t_noun in i2t_nouns:\n",
    "            if len(i2t_noun) > 1:\n",
    "                noun_list.append(i2t_noun)\n",
    "\n",
    "        noun_list = list(set(noun_list))\n",
    "        return noun_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 장르별 단어 txt파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# act_nouns = []\n",
    "# ani_nouns = []\n",
    "# com_nouns = []\n",
    "# dra_nouns = []\n",
    "# hor_nouns = []\n",
    "# etc_nouns = []\n",
    "\n",
    "# for num in tqdm(range(len(X))):\n",
    "#     img = X[num]\n",
    "\n",
    "#     try:\n",
    "#         ocr = Ocr(img)\n",
    "#         # ocr.text_detect()\n",
    "#         i2t_text = ocr.image_to_text()\n",
    "#         # print(y[num])\n",
    "#         gn = Get_Nouns(i2t_text)\n",
    "#         nouns = gn.get_nouns_list()\n",
    "#         nouns = list(set(nouns))\n",
    "#     except:\n",
    "#         print(num)\n",
    "\n",
    "#     if y[num] == '액션':\n",
    "#         for noun in nouns:\n",
    "#             act_nouns.append(noun)\n",
    "#     elif y[num] == '애니메이션':\n",
    "#         for noun in nouns:\n",
    "#             ani_nouns.append(noun)\n",
    "#     elif y[num] == '코미디':\n",
    "#         for noun in nouns:\n",
    "#             com_nouns.append(noun)\n",
    "#     elif y[num] == '드라마':\n",
    "#         for noun in nouns:\n",
    "#             dra_nouns.append(noun)\n",
    "#     elif y[num] == '공포(호러)':\n",
    "#         for noun in nouns:\n",
    "#             hor_nouns.append(noun)\n",
    "#     else:\n",
    "#         for noun in nouns:\n",
    "#             etc_nouns.append(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(act_nouns)\n",
    "# print(ani_nouns)\n",
    "# print(com_nouns)\n",
    "# print(dra_nouns)\n",
    "# print(hor_nouns)\n",
    "# print(etc_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act_nouns = list(set(act_nouns))\n",
    "# ani_nouns = list(set(ani_nouns))\n",
    "# com_nouns = list(set(com_nouns))\n",
    "# dra_nouns = list(set(dra_nouns))\n",
    "# hor_nouns = list(set(hor_nouns))\n",
    "# etc_nouns = list(set(etc_nouns))\n",
    "\n",
    "# print(len(act_nouns))\n",
    "# print(len(ani_nouns))\n",
    "# print(len(com_nouns))\n",
    "# print(len(dra_nouns))\n",
    "# print(len(hor_nouns))\n",
    "# print(len(etc_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# genre = ['액션', '애니매이션', '코미디', '드라마', '공포(호러)', '기타']\n",
    "\n",
    "# # 문서 코퍼스 생성\n",
    "# corpus = [\n",
    "#     ' '.join(act_nouns),\n",
    "#     ' '.join(ani_nouns),\n",
    "#     ' '.join(com_nouns),\n",
    "#     ' '.join(dra_nouns),\n",
    "#     ' '.join(hor_nouns),\n",
    "#     ' '.join(etc_nouns)\n",
    "# ]\n",
    "\n",
    "# # TF-IDF 벡터화\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# # 입력 단어\n",
    "# input_word = '감동'\n",
    "\n",
    "# # 입력 단어를 TF-IDF 벡터로 변환\n",
    "# input_vector = tfidf_vectorizer.transform([input_word])\n",
    "\n",
    "# # 각 카테고리와의 코사인 유사도 계산\n",
    "# similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "\n",
    "# print(similarities)\n",
    "# print(similarities.argmax())\n",
    "# # 유사도가 가장 높은 카테고리 선택\n",
    "# most_similar_category = genre[similarities.argmax()]\n",
    "\n",
    "# # 결과 출력\n",
    "# print(f\"입력 단어 '{input_word}'와(과) 가장 유사한 카테고리: {most_similar_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act_nouns\n",
    "# ani_nouns\n",
    "# com_nouns\n",
    "# dra_nouns\n",
    "# hor_nouns\n",
    "# etc_nouns \n",
    "\n",
    "# 리스트를 텍스트 파일로 저장\n",
    "# with open('c:/3rd_project/data/etc_nouns.txt', 'w', encoding='utf-8') as f:\n",
    "#     for item in etc_nouns:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 장르별 단어 txt파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words_from_file(file_path):\n",
    "    words = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # 줄바꿈 문자를 제거하고 단어를 리스트에 추가\n",
    "            word = line.strip()\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "# 파일로부터 단어 리스트 불러오기\n",
    "act_nouns = read_words_from_file('c:/3rd_project/data/act_nouns.txt')\n",
    "ani_nouns = read_words_from_file('c:/3rd_project/data/ani_nouns.txt')\n",
    "com_nouns = read_words_from_file('c:/3rd_project/data/com_nouns.txt')\n",
    "dra_nouns = read_words_from_file('c:/3rd_project/data/dra_nouns.txt')\n",
    "hor_nouns = read_words_from_file('c:/3rd_project/data/hor_nouns.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 장르별 단어 빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "num = 0\n",
    "img = X[num]\n",
    "genre = y[num]\n",
    "\n",
    "# 이미지 텍스트 추출\n",
    "ocr = Ocr(img)\n",
    "ocr.text_detect()\n",
    "i2t_text = ocr.image_to_text()\n",
    "# print(y[num])\n",
    "gn = Get_Nouns(i2t_text)\n",
    "nouns = gn.get_nouns_list()\n",
    "\n",
    "act_freq = 0\n",
    "ani_freq = 0\n",
    "com_freq = 0\n",
    "dra_freq = 0\n",
    "hor_freq = 0\n",
    "\n",
    "print(len(nouns))\n",
    "\n",
    "# 입력한 단어들의 빈도수 확인\n",
    "for word in nouns:\n",
    "    if word in act_nouns:\n",
    "        print(f\"액션 단어 : {word}\")\n",
    "        act_freq += 1\n",
    "    elif word in ani_nouns:\n",
    "        print(f\"애니 단어 : {word}\")\n",
    "        ani_freq += 1\n",
    "    elif word in com_nouns:\n",
    "        print(f\"코미디 단어 : {word}\")\n",
    "        com_freq += 1\n",
    "    elif word in dra_nouns:\n",
    "        print(f\"드라마 단어 : {word}\")\n",
    "        dra_freq += 1\n",
    "    elif word in hor_nouns:\n",
    "        print(f\"공포 단어 : {word}\")\n",
    "        hor_freq += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(f\"장르 : {genre}\")\n",
    "print(f\"액션 장르의 빈도수: {act_freq}\")\n",
    "print(f\"애니메이션 장르의 빈도수: {ani_freq}\")\n",
    "print(f\"코미디 장르의 빈도수: {com_freq}\")\n",
    "print(f\"드라마 장르의 빈도수: {dra_freq}\")\n",
    "print(f\"공포(호러) 장르의 빈도수: {hor_freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2t_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_freq</th>\n",
       "      <th>ani_freq</th>\n",
       "      <th>com_freq</th>\n",
       "      <th>dra_freq</th>\n",
       "      <th>hor_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [act_freq, ani_freq, com_freq, dra_freq, hor_freq]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['act_freq', 'ani_freq', 'com_freq', 'dra_freq', 'hor_freq']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 54/1287 [02:38<54:39,  2.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 58/1287 [02:49<54:44,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 127/1287 [06:21<1:01:12,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 132/1287 [06:39<1:03:29,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 134/1287 [06:45<1:04:22,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 158/1287 [07:59<58:14,  3.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 186/1287 [09:25<53:34,  2.92s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 211/1287 [10:40<50:36,  2.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 320/1287 [16:09<49:50,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 382/1287 [19:16<42:02,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 438/1287 [22:05<45:24,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 566/1287 [28:34<38:26,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 735/1287 [36:00<25:01,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 764/1287 [37:17<23:46,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 810/1287 [39:24<21:33,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 842/1287 [40:50<19:06,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 844/1287 [40:54<18:45,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 845/1287 [40:57<18:39,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 885/1287 [42:47<16:41,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 920/1287 [44:21<15:23,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 938/1287 [45:11<16:36,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 952/1287 [45:47<15:24,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 968/1287 [46:35<16:15,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1062/1287 [51:31<11:29,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1095/1287 [53:16<09:56,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1104/1287 [53:44<10:09,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1136/1287 [55:25<07:35,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1224/1287 [1:00:02<03:11,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1260/1287 [1:01:54<01:23,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1287/1287 [1:03:20<00:00,  2.95s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_freq</th>\n",
       "      <th>ani_freq</th>\n",
       "      <th>com_freq</th>\n",
       "      <th>dra_freq</th>\n",
       "      <th>hor_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1287 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     act_freq ani_freq com_freq dra_freq hor_freq\n",
       "5718        2        3        0        0        0\n",
       "5719        4        0        2        2        0\n",
       "5720        1        0        0        0        0\n",
       "5721        2        0        0        1        0\n",
       "5722        0        0        0        0        0\n",
       "...       ...      ...      ...      ...      ...\n",
       "7000        3        1        0        0        0\n",
       "7001        2        1        0        1        0\n",
       "7002        0        0        0        0        0\n",
       "7003       12        2        3        2        0\n",
       "7004        2        0        0        0        0\n",
       "\n",
       "[1287 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "num = list(range(5718, 7005))\n",
    "\n",
    "for num in tqdm(num):\n",
    "    # print(num)\n",
    "    img = X[num]\n",
    "    genre = y[num]\n",
    "\n",
    "    try:\n",
    "        # 이미지 텍스트 추출\n",
    "        ocr = Ocr(img)\n",
    "        # ocr.text_detect()\n",
    "        i2t_text = ocr.image_to_text()\n",
    "        # print(y[num])\n",
    "        gn = Get_Nouns(i2t_text)\n",
    "        nouns = gn.get_nouns_list()\n",
    "\n",
    "        act_freq = 0\n",
    "        ani_freq = 0\n",
    "        com_freq = 0\n",
    "        dra_freq = 0\n",
    "        hor_freq = 0\n",
    "\n",
    "        # 입력한 단어들의 빈도수 확인\n",
    "        for word in nouns:\n",
    "            if word in act_nouns:\n",
    "                act_freq += 1\n",
    "            elif word in ani_nouns:\n",
    "                ani_freq += 1\n",
    "            elif word in com_nouns:\n",
    "                com_freq += 1\n",
    "            elif word in dra_nouns:\n",
    "                dra_freq += 1\n",
    "            elif word in hor_nouns:\n",
    "                hor_freq += 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        df.loc[num, 'act_freq'] = act_freq\n",
    "        df.loc[num, 'ani_freq'] = ani_freq\n",
    "        df.loc[num, 'com_freq'] = com_freq\n",
    "        df.loc[num, 'dra_freq'] = dra_freq\n",
    "        df.loc[num, 'hor_freq'] = hor_freq\n",
    "\n",
    "    except:\n",
    "        print(num)\n",
    "        df.loc[num, 'act_freq'] = 0\n",
    "        df.loc[num, 'ani_freq'] = 0\n",
    "        df.loc[num, 'com_freq'] = 0\n",
    "        df.loc[num, 'dra_freq'] = 0\n",
    "        df.loc[num, 'hor_freq'] = 0\n",
    "\n",
    "    df.to_csv(\"c:/3rd_project/data/Train/freq_1011_2.csv\", index=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_freq</th>\n",
       "      <th>ani_freq</th>\n",
       "      <th>com_freq</th>\n",
       "      <th>dra_freq</th>\n",
       "      <th>hor_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5715</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5718 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      act_freq  ani_freq  com_freq  dra_freq  hor_freq\n",
       "0            1         1         1         0         0\n",
       "1            0         0         0         0         0\n",
       "2            7         2         1         1         0\n",
       "3            1         0         0         0         0\n",
       "4            0         0         0         0         0\n",
       "...        ...       ...       ...       ...       ...\n",
       "5713         0         0         0         0         0\n",
       "5714         6         0         0         0         0\n",
       "5715         6         1         0         2         0\n",
       "5716         4         1         1         0         0\n",
       "5717         2         2         0         0         0\n",
       "\n",
       "[5718 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('c:/3rd_project/data/Train/freq_1011.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_freq</th>\n",
       "      <th>ani_freq</th>\n",
       "      <th>com_freq</th>\n",
       "      <th>dra_freq</th>\n",
       "      <th>hor_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7005 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     act_freq ani_freq com_freq dra_freq hor_freq\n",
       "0           1        1        1        0        0\n",
       "1           0        0        0        0        0\n",
       "2           7        2        1        1        0\n",
       "3           1        0        0        0        0\n",
       "4           0        0        0        0        0\n",
       "...       ...      ...      ...      ...      ...\n",
       "7000        3        1        0        0        0\n",
       "7001        2        1        0        1        0\n",
       "7002        0        0        0        0        0\n",
       "7003       12        2        3        2        0\n",
       "7004        2        0        0        0        0\n",
       "\n",
       "[7005 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.concat([df2, df], ignore_index=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"c:/3rd_project/data/Train/freq_1012.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
